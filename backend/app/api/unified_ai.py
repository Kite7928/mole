"""
AIæœåŠ¡APIè·¯ç”± - ç®€åŒ–ç‰ˆ
æ”¯æŒç”Ÿæˆæ ‡é¢˜ã€ç”Ÿæˆæ­£æ–‡ã€ä¸€é”®å…¨è‡ªåŠ¨ç”Ÿæˆ
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from openai import AsyncOpenAI
import httpx
import json
from ..services.news_fetcher import news_fetcher_service
from ..services.wechat_service import wechat_service
from ..services.image_generation_service import image_generation_service
from ..models.news import NewsSource
from ..models.config import AppConfig
from ..core.database import get_db
from ..core.config import settings
from ..core.logger import logger

router = APIRouter()


class _DefaultAIWriterService:
    """å…¼å®¹æ—§æµ‹è¯•æ³¨å…¥çš„è½»é‡ AI å†™ä½œæœåŠ¡"""

    async def generate_titles(self, topic: str, count: int = 5, model: Optional[str] = None):
        return [
            {"title": f"{topic}ï¼šä½ åº”è¯¥çŸ¥é“çš„3ä»¶äº‹", "click_rate": 80.0},
            {"title": f"{topic}è¶‹åŠ¿è§‚å¯Ÿï¼šæœºä¼šä¸æŒ‘æˆ˜", "click_rate": 78.0},
        ][: max(1, min(count, 10))]

    async def generate_content(
        self,
        topic: str,
        title: str,
        style: str = "professional",
        length: str = "medium",
        model: Optional[str] = None,
    ):
        content = (
            f"# {title}\n\n"
            f"æœ¬æ–‡å›´ç»•â€œ{topic}â€è¿›è¡Œåˆ†æï¼Œé£æ ¼ï¼š{style}ï¼Œç¯‡å¹…ï¼š{length}ã€‚\n\n"
            "## æ ¸å¿ƒè§‚ç‚¹\n- è§‚ç‚¹ä¸€\n- è§‚ç‚¹äºŒ\n\n"
            "## è¡ŒåŠ¨å»ºè®®\nå»ºè®®å…ˆå°èŒƒå›´éªŒè¯ï¼Œå†é€æ­¥æ”¾å¤§ã€‚"
        )
        return {
            "content": content,
            "summary": f"å›´ç»•{topic}çš„å†…å®¹è‰ç¨¿",
            "quality_score": 75.0,
        }


ai_writer_service = _DefaultAIWriterService()
image_service = image_generation_service


def _allow_mock_fallback() -> bool:
    """æ˜¯å¦å…è®¸è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼ˆé»˜è®¤å…³é—­ï¼Œé¿å…ç”Ÿäº§ç¯å¢ƒè¯¯ç”¨ï¼‰"""
    return bool(settings.ALLOW_MOCK_FALLBACK or settings.DEBUG)


async def get_config_from_db(db: AsyncSession) -> Optional[AppConfig]:
    """
    ä»æ•°æ®åº“è·å–é…ç½®ï¼Œå¦‚æœæ•°æ®åº“é…ç½®ä¸å®Œæ•´åˆ™è‡ªåŠ¨å¡«å……é»˜è®¤å€¼
    """
    query = select(AppConfig).order_by(AppConfig.id.desc())
    result = await db.execute(query)
    config = result.scalar_one_or_none()

    if not config:
        return None

    if not config.api_key:
        logger.warning("æ•°æ®åº“ä¸­æœªé…ç½® API Key")
        return None

    # è¡¥å……é»˜è®¤é…ç½®å€¼
    provider = config.ai_provider or "deepseek"

    # æ ¹æ®æä¾›å•†è®¾ç½®é»˜è®¤å€¼
    if provider == "deepseek":
        if not config.base_url:
            config.base_url = "https://api.deepseek.com/v1"
        if not config.model:
            config.model = "deepseek-chat"
    elif provider == "openai":
        if not config.base_url:
            config.base_url = "https://api.openai.com/v1"
        if not config.model:
            config.model = "gpt-4-turbo-preview"
    elif provider == "gemini":
        if not config.base_url:
            config.base_url = "https://generativelanguage.googleapis.com/v1beta"
        if not config.model:
            config.model = "gemini-pro"
    elif provider == "zhipu":
        if not config.base_url:
            config.base_url = "https://open.bigmodel.cn/api/paas/v4"
        if not config.model:
            config.model = "glm-4-flash"
    else:
        # æœªçŸ¥æä¾›å•†ï¼Œä½¿ç”¨é€šç”¨é»˜è®¤å€¼
        if not config.base_url:
            config.base_url = "https://api.deepseek.com/v1"
        if not config.model:
            config.model = "deepseek-chat"

    logger.info(f"ä½¿ç”¨æ•°æ®åº“é…ç½®: æä¾›å•†={provider}, æ¨¡å‹={config.model}")
    return config


class GenerateTitlesRequest(BaseModel):
    """ç”Ÿæˆæ ‡é¢˜è¯·æ±‚"""
    topic: str = Field(..., description="æ–‡ç« ä¸»é¢˜")
    count: int = Field(default=5, ge=1, le=10, description="ç”Ÿæˆæ•°é‡")
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„æ¨¡å‹ï¼ˆopenai/deepseekï¼‰")


class GenerateContentRequest(BaseModel):
    """ç”Ÿæˆæ­£æ–‡è¯·æ±‚"""
    topic: str = Field(..., description="æ–‡ç« ä¸»é¢˜")
    title: str = Field(..., description="æ–‡ç« æ ‡é¢˜")
    style: str = Field(
        default="professional",
        description="å†™ä½œé£æ ¼ï¼šprofessional(ä¸“ä¸š)/casual(è½»æ¾)/humor(å¹½é»˜)/story(æ•…äº‹)/emotion(æƒ…æ„Ÿ)/dry_goods(å¹²è´§)/opinion(è§‚ç‚¹)/trend(çƒ­ç‚¹)"
    )
    length: str = Field(default="medium", description="é•¿åº¦ï¼šshort(800-1000å­—)/medium(1500-2000å­—)/long(2500-3000å­—)")
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„æ¨¡å‹")


class AutoGenerateRequest(BaseModel):
    """ä¸€é”®å…¨è‡ªåŠ¨ç”Ÿæˆè¯·æ±‚"""
    topic: str = Field(..., description="æ–‡ç« ä¸»é¢˜")
    source_url: Optional[str] = Field(None, description="æ¥æºé“¾æ¥")
    enable_wechat_publish: bool = Field(default=False, description="æ˜¯å¦å‘å¸ƒåˆ°å¾®ä¿¡")
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„æ¨¡å‹")


class TitleResponse(BaseModel):
    """æ ‡é¢˜å“åº”"""
    title: str
    click_rate: float


class TitleScoreRequest(BaseModel):
    """æ ‡é¢˜è¯„åˆ†è¯·æ±‚"""
    title: str = Field(..., description="å¾…è¯„åˆ†çš„æ ‡é¢˜")
    topic: Optional[str] = Field(None, description="æ–‡ç« ä¸»é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºæ›´å‡†ç¡®è¯„åˆ†ï¼‰")
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„æ¨¡å‹")


class TitleScoreResponse(BaseModel):
    """æ ‡é¢˜è¯„åˆ†å“åº”"""
    score: int = Field(..., description="æ€»åˆ†(0-100)")
    click_rate: float = Field(..., description="é¢„ä¼°ç‚¹å‡»ç‡(0-100%)")
    analysis: str = Field(..., description="ç»¼åˆè¯„ä»·")
    dimensions: Dict[str, Any] = Field(..., description="å„ç»´åº¦è¯„åˆ†")
    suggestions: List[str] = Field(..., description="ä¼˜åŒ–å»ºè®®")


class ContentResponse(BaseModel):
    """æ­£æ–‡å“åº”"""
    content: str
    summary: str
    quality_score: float
    seo_data: Optional[Dict[str, Any]] = None


@router.post("/generate-titles", response_model=List[TitleResponse])
async def generate_titles(request: GenerateTitlesRequest, db: AsyncSession = Depends(get_db)):
    """
    ç”Ÿæˆæ–‡ç« æ ‡é¢˜

    Args:
        request: ç”Ÿæˆæ ‡é¢˜è¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        æ ‡é¢˜åˆ—è¡¨
    """
    try:
        if not isinstance(ai_writer_service, _DefaultAIWriterService):
            try:
                return await ai_writer_service.generate_titles(
                    topic=request.topic,
                    count=request.count,
                    model=request.model,
                )
            except Exception:
                pass

        # ä»æ•°æ®åº“è·å–é…ç½®
        config = await get_config_from_db(db)
        if not config:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®AIå‚æ•°")
        if not config.api_key:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®AI API Key")

        logger.info(f"ç”Ÿæˆæ ‡é¢˜ï¼Œä¸»é¢˜: {request.topic}, æ•°é‡: {request.count}")

        # é€‰æ‹©æ¨¡å‹å’ŒåŸºç¡€URLï¼Œä½¿ç”¨é»˜è®¤å€¼ç¡®ä¿é…ç½®å®Œæ•´
        model = request.model or config.model or "deepseek-chat"
        base_url = config.base_url or "https://api.deepseek.com/v1"

        if not config.api_key:
            raise HTTPException(status_code=400, detail="æœªé…ç½®AI API Keyï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®")

        logger.info(f"ä½¿ç”¨AIæ¨¡å‹: {model}, APIåœ°å€: {base_url}")

        # åˆ›å»ºè‡ªå®šä¹‰ httpx å®¢æˆ·ç«¯ï¼ˆä¿®å¤ Windows SSL é—®é¢˜ï¼‰
        http_client = httpx.AsyncClient(
            verify=False,  # ç¦ç”¨ SSL éªŒè¯ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
            timeout=httpx.Timeout(120.0, connect=10.0, read=60.0, write=60.0),
            follow_redirects=True,
            limits=httpx.Limits(max_keepalive_connections=5, max_connections=10),
            trust_env=False,
        )
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨async withè‡ªåŠ¨ç®¡ç†è¿æ¥ï¼‰
        async with AsyncOpenAI(
            api_key=config.api_key,
            base_url=base_url,
            http_client=http_client
        ) as client:
            # æ„å»ºæç¤ºè¯ - è‡ªåª’ä½“çˆ†æ¬¾æ ‡é¢˜å…¬å¼
            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‡ªåª’ä½“æ ‡é¢˜åˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿åˆ›ä½œå¾®ä¿¡å…¬ä¼—å·çˆ†æ¬¾æ ‡é¢˜ã€‚

è¯·ä¸ºä¸»é¢˜ã€Œ{request.topic}ã€ç”Ÿæˆ {request.count} ä¸ªé«˜ç‚¹å‡»ç‡çš„æ ‡é¢˜ã€‚

## çˆ†æ¬¾æ ‡é¢˜åˆ›ä½œæŠ€å·§ï¼ˆè¯·çµæ´»è¿ç”¨ï¼‰ï¼š
1. **æ•°å­—æ³•**ï¼šç”¨å…·ä½“æ•°å­—å¢å¼ºå¯ä¿¡åº¦ï¼Œå¦‚ã€Œ3ä¸ªæ–¹æ³•ã€ã€Œ5ä¸ªæŠ€å·§ã€ã€Œ90%çš„äººä¸çŸ¥é“ã€
2. **æ‚¬å¿µæ³•**ï¼šåˆ¶é€ å¥½å¥‡å¿ƒï¼Œå¦‚ã€ŒåŸæ¥...ã€ã€Œç«Ÿç„¶...ã€ã€Œä¸‡ä¸‡æ²¡æƒ³åˆ°...ã€
3. **ç—›ç‚¹æ³•**ï¼šç›´å‡»è¯»è€…ç—›ç‚¹ï¼Œå¦‚ã€Œä½ è¿˜åœ¨...ï¼Ÿã€ã€Œä¸ºä»€ä¹ˆä½ æ€»æ˜¯...ã€
4. **å¯¹æ¯”æ³•**ï¼šå¼ºçƒˆåå·®å¸å¼•çœ¼çƒï¼Œå¦‚ã€Œä»...åˆ°...ã€ã€Œä¸è¦...è€Œè¦...ã€
5. **æƒå¨æ³•**ï¼šå€ŸåŠ©æƒå¨èƒŒä¹¦ï¼Œå¦‚ã€Œäººæ°‘æ—¥æŠ¥æ¨èã€ã€Œä¸“å®¶æ­ç§˜ã€
6. **æƒ…ç»ªå…±é¸£**ï¼šè§¦å‘æƒ…æ„Ÿå…±é¸£ï¼Œå¦‚ã€Œçœ‹å®Œæ²‰é»˜äº†...ã€ã€Œå¤ªæ‰å¿ƒäº†ã€
7. **å®ç”¨ä»·å€¼**ï¼šå¼ºè°ƒå¹²è´§å’Œå®ç”¨æ€§ï¼Œå¦‚ã€Œæ”¶è—ã€ã€Œå¿…çœ‹ã€ã€Œä¿å§†çº§æ•™ç¨‹ã€

## æ ‡é¢˜è¦æ±‚ï¼š
- é•¿åº¦æ§åˆ¶åœ¨18-28å­—ä¹‹é—´ï¼ˆæœ€é€‚åˆå¾®ä¿¡ç”Ÿæ€ï¼‰
- é¿å…æ ‡é¢˜å…šï¼Œå†…å®¹ä¸æ ‡é¢˜è¦ç›¸ç¬¦
- çªå‡ºç§‘æŠ€æ„Ÿå’Œå®ç”¨æ€§
- é€‚åˆæ‰‹æœºç«¯å±•ç¤ºï¼Œå‰18å­—è¦æœ‰å¸å¼•åŠ›

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{"title": "æ ‡é¢˜1", "click_rate": 85}},
  {{"title": "æ ‡é¢˜2", "click_rate": 80}}
]
click_rateä¸ºé¢„æµ‹ç‚¹å‡»ç‡ï¼ˆ0-100ï¼‰ï¼Œæ ¹æ®æ ‡é¢˜çš„å¸å¼•åŠ›å’Œè½¬åŒ–æ½œåŠ›è¯„åˆ†"""

            # è°ƒç”¨AI
            response = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¬ä¼—å·æ ‡é¢˜åˆ›ä½œä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )

            content = response.choices[0].message.content

            # è§£æJSONå“åº”
            import json
            import re

            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)

            titles = json.loads(content)

            return [
                TitleResponse(title=t["title"], click_rate=t.get("click_rate", 80))
                for t in titles
            ]

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {type(e).__name__}: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        if _allow_mock_fallback():
            logger.warning("AI æ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œå·²å¯ç”¨æ¨¡æ‹Ÿæ ‡é¢˜é™çº§")
            fallback_titles = [
                {"title": f"æ·±åº¦è§£æï¼š{request.topic}èƒŒåçš„çœŸç›¸", "click_rate": 85},
                {"title": f"90%çš„äººéƒ½ä¸çŸ¥é“çš„{request.topic}ç§˜è¯€", "click_rate": 88},
                {"title": f"ä»å…¥é—¨åˆ°ç²¾é€šï¼š{request.topic}å®Œæ•´æŒ‡å—", "click_rate": 82},
                {"title": f"æ­ç§˜{request.topic}ï¼šè¡Œä¸šä¸“å®¶éƒ½åœ¨ç”¨çš„æ–¹æ³•", "click_rate": 80},
                {"title": f"ä¸ºä»€ä¹ˆä½ åº”è¯¥å…³æ³¨{request.topic}ï¼Ÿçœ‹å®Œå°±æ‡‚äº†", "click_rate": 78},
            ]

            return [
                TitleResponse(title=t["title"], click_rate=t["click_rate"])
                for t in fallback_titles[:request.count]
            ]

        raise HTTPException(
            status_code=502,
            detail={
                "message": "AI æ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–ç¨åé‡è¯•",
                "error_type": "ai_generate_titles_failed",
                "allow_mock_fallback": False,
                "debug_error": str(e) if settings.DEBUG else None,
            }
        )


@router.post("/generate-content", response_model=ContentResponse)
async def generate_content(request: GenerateContentRequest, db: AsyncSession = Depends(get_db)):
    """
    ç”Ÿæˆæ–‡ç« æ­£æ–‡
    
    Args:
        request: ç”Ÿæˆæ­£æ–‡è¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
    
    Returns:
        æ­£æ–‡å†…å®¹
    """
    try:
        if not isinstance(ai_writer_service, _DefaultAIWriterService):
            try:
                generated = await ai_writer_service.generate_content(
                    topic=request.topic,
                    title=request.title,
                    style=request.style,
                    length=request.length,
                    model=request.model,
                )
                if generated:
                    return generated
            except Exception:
                pass

        # ä»æ•°æ®åº“è·å–é…ç½®
        config = await get_config_from_db(db)
        if not config or not config.api_key:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®AI API Key")
        
        logger.info(f"ç”Ÿæˆæ­£æ–‡ï¼Œæ ‡é¢˜: {request.title}")

        # é€‰æ‹©æ¨¡å‹å’ŒåŸºç¡€URLï¼Œä½¿ç”¨é»˜è®¤å€¼ç¡®ä¿é…ç½®å®Œæ•´
        model = request.model or config.model or "deepseek-chat"
        base_url = config.base_url or "https://api.deepseek.com/v1"

        logger.info(f"ä½¿ç”¨AIæ¨¡å‹: {model}, APIåœ°å€: {base_url}")

        # é•¿åº¦æ˜ å°„
        length_map = {
            "short": "800-1000å­—",
            "medium": "1500-2000å­—",
            "long": "2500-3000å­—"
        }
        
        # é£æ ¼æ˜ å°„ - è‡ªåª’ä½“åˆ›ä½œé£æ ¼
        style_map = {
            "professional": "ä¸“ä¸šä¸¥è°¨ï¼Œæ·±åº¦åˆ†æï¼Œé€‚åˆè¡Œä¸šæ´å¯Ÿå’ŒæŠ€æœ¯è§£è¯»",
            "casual": "è½»æ¾æ´»æ³¼ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶",
            "humor": "å¹½é»˜é£è¶£ï¼Œç”ŸåŠ¨æœ‰è¶£ï¼Œç”¨æ®µå­å’Œæ¢—è®©å†…å®¹æ›´ç”ŸåŠ¨",
            "story": "æ•…äº‹å™è¿°å‹ï¼Œç”¨çœŸå®æ¡ˆä¾‹å’Œæ•…äº‹æ‰“åŠ¨è¯»è€…",
            "emotion": "æƒ…æ„Ÿå…±é¸£å‹ï¼Œç›´å‡»å†…å¿ƒï¼Œå¼•å‘è¯»è€…æƒ…ç»ªå…±æŒ¯",
            "dry_goods": "å¹²è´§åˆ†äº«å‹ï¼Œå®ç”¨è‡³ä¸Šï¼Œæ­¥éª¤æ¸…æ™°å¯æ“ä½œ",
            "opinion": "è§‚ç‚¹è¯„è®ºå‹ï¼ŒçŠ€åˆ©ç‹¬åˆ°ï¼Œæ•¢äºè¡¨è¾¾ç«‹åœº",
            "trend": "çƒ­ç‚¹è§£è¯»å‹ï¼Œç´§è·Ÿæ—¶äº‹ï¼Œå¿«é€Ÿåˆ†æçƒ­ç‚¹äº‹ä»¶"
        }
        
        # æ„å»ºæç¤ºè¯ - è‡ªåª’ä½“çˆ†æ¬¾æ–‡ç« ç»“æ„
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‡ªåª’ä½“å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿æ’°å†™å¾®ä¿¡å…¬ä¼—å·çˆ†æ¬¾æ–‡ç« ã€‚

## æ–‡ç« ä»»åŠ¡
- **æ ‡é¢˜**ï¼š{request.title}
- **ä¸»é¢˜**ï¼š{request.topic}
- **å­—æ•°è¦æ±‚**ï¼š{length_map.get(request.length, '1500-2000å­—')}
- **é£æ ¼è¦æ±‚**ï¼š{style_map.get(request.style, 'ä¸“ä¸šä¸¥è°¨ï¼Œæ·±åº¦åˆ†æ')}

## çˆ†æ¬¾æ–‡ç« ç»“æ„è¦æ±‚ï¼ˆè¯·ä¸¥æ ¼éµå¾ªï¼‰ï¼š

### 1. å¼€å¤´é’©å­ï¼ˆ100-200å­—ï¼‰
- ç”¨æ‚¬å¿µã€ç—›ç‚¹ã€æƒŠäººæ•°æ®æˆ–æ•…äº‹å¼€åœº
- ç¬¬ä¸€å¥è¯å°±è¦æŠ“ä½è¯»è€…æ³¨æ„åŠ›
- è®©è¯»è€…äº§ç”Ÿã€Œè¿™è¯´çš„å°±æ˜¯æˆ‘ã€æˆ–ã€Œæˆ‘æƒ³çŸ¥é“ç­”æ¡ˆã€çš„æ„Ÿè§‰

### 2. ç—›ç‚¹å…±é¸£ï¼ˆ200-300å­—ï¼‰
- æè¿°ç›®æ ‡è¯»è€…é¢ä¸´çš„å›°å¢ƒæˆ–çƒ¦æ¼
- ç”¨å…·ä½“åœºæ™¯è®©è¯»è€…äº§ç”Ÿä»£å…¥æ„Ÿ
- å¼•å‘æƒ…ç»ªå…±é¸£ï¼Œè®©è¯»è€…è§‰å¾—ã€Œå¤ªæ‡‚æˆ‘äº†ã€

### 3. æ ¸å¿ƒå†…å®¹ï¼ˆä¸»ä½“éƒ¨åˆ†ï¼‰
- ç”¨3-5ä¸ªå°æ ‡é¢˜ç»„ç»‡å†…å®¹
- æ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰å®ç”¨ä»·å€¼
- ç»“åˆæ¡ˆä¾‹ã€æ•°æ®ã€æ•…äº‹å¢åŠ å¯ä¿¡åº¦
- é€‚å½“ä½¿ç”¨**åŠ ç²—**çªå‡ºé‡ç‚¹
- æ®µè½æ§åˆ¶åœ¨3-4è¡Œï¼Œé€‚åˆæ‰‹æœºé˜…è¯»

### 4. é‡‘å¥ç‚¹ç¼€
- åœ¨æ–‡ä¸­ç©¿æ’2-3ä¸ªé‡‘å¥ï¼ˆç”¨å¼•ç”¨æ ¼å¼ï¼‰
- é‡‘å¥è¦ç®€æ´æœ‰åŠ›ï¼Œå®¹æ˜“ä¼ æ’­

### 5. ç»“å°¾å‡åï¼ˆ150-200å­—ï¼‰
- æ€»ç»“æ ¸å¿ƒè§‚ç‚¹
- ç»™å‡ºè¡ŒåŠ¨å»ºè®®æˆ–æ€è€ƒæ–¹å‘
- ç”¨é‡‘å¥æˆ–å±•æœ›æ”¶å°¾

### 6. äº’åŠ¨å¼•å¯¼ï¼ˆæœ€åï¼‰
- å¼•å¯¼è¯»è€…ç‚¹èµã€åœ¨çœ‹ã€è½¬å‘
- å¯ä»¥ç”¨é—®å¥å¼•å‘è¯„è®ºåŒºäº’åŠ¨

## æ’ç‰ˆè¦æ±‚ï¼š
- ä½¿ç”¨Markdownæ ¼å¼ï¼ˆ# ## ### ç­‰æ ‡é¢˜å±‚çº§ï¼‰
- é€‚å½“ä½¿ç”¨åˆ—è¡¨ã€å¼•ç”¨ç­‰æ ¼å¼
- å…³é”®ä¿¡æ¯ç”¨**åŠ ç²—**çªå‡º
- æ®µè½ä¹‹é—´ç©ºä¸€è¡Œ

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«ã€Œä»¥ä¸‹æ˜¯æ–‡ç« ã€ç­‰è¯´æ˜æ–‡å­—ã€‚"""

        # åˆ›å»ºè‡ªå®šä¹‰ httpx å®¢æˆ·ç«¯ï¼ˆä¿®å¤ Windows SSL é—®é¢˜ï¼‰
        http_client = httpx.AsyncClient(
            verify=False,  # ç¦ç”¨ SSL éªŒè¯ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
            timeout=httpx.Timeout(300.0, connect=10.0),
            follow_redirects=True,
            trust_env=False,
        )
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨async withè‡ªåŠ¨ç®¡ç†è¿æ¥ï¼‰
        async with AsyncOpenAI(
            api_key=config.api_key,
            base_url=base_url,
            http_client=http_client
        ) as client:
            # è°ƒç”¨AI
            response = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿æ’°å†™æ·±åº¦ç§‘æŠ€æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )

            content = response.choices[0].message.content

            # ç”Ÿæˆæ‘˜è¦
            summary = content[:150] + "..." if len(content) > 150 else content

            # è¯„ä¼°è´¨é‡
            quality_score = _assess_quality(content)

            logger.info(f"å†…å®¹ç”Ÿæˆå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {quality_score}")

            return ContentResponse(
                content=content,
                summary=summary,
                quality_score=quality_score
            )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"ç”Ÿæˆæ­£æ–‡å¤±è´¥: {type(e).__name__}: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        if _allow_mock_fallback():
            logger.warning("AI æ­£æ–‡ç”Ÿæˆå¤±è´¥ï¼Œå·²å¯ç”¨æ¨¡æ‹Ÿæ­£æ–‡é™çº§")
            style_templates = {
                "professional": f"""# {request.title}

åœ¨å½“ä»Šå¿«é€Ÿå‘å±•çš„æ—¶ä»£ï¼Œ{request.topic}å·²ç»æˆä¸ºä¸å¯å¿½è§†çš„é‡è¦è¯é¢˜ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æå…¶èƒŒåçš„æŠ€æœ¯åŸç†å’Œåº”ç”¨åœºæ™¯ã€‚

## æ ¸å¿ƒæ¦‚å¿µè§£æ

{request.topic}ä½œä¸ºä¸€é¡¹å‰æ²¿æŠ€æœ¯ï¼Œå…·æœ‰ä»¥ä¸‹å‡ ä¸ªå…³é”®ç‰¹å¾ï¼š

- **åˆ›æ–°æ€§**ï¼šé‡‡ç”¨å…ˆè¿›çš„æŠ€æœ¯æ¶æ„ï¼Œçªç ´äº†ä¼ ç»Ÿé™åˆ¶
- **å®ç”¨æ€§**ï¼šè§£å†³å®é™…ä¸šåŠ¡ç—›ç‚¹ï¼Œæå‡å·¥ä½œæ•ˆç‡
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒçµæ´»çš„é…ç½®å’Œæ‰©å±•éœ€æ±‚

## å®é™…åº”ç”¨æ¡ˆä¾‹

ä»¥æŸçŸ¥åä¼ä¸šä¸ºä¾‹ï¼Œé€šè¿‡å¼•å…¥{request.topic}ï¼Œå®ç°äº†ï¼š

1. ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–ï¼Œæ•ˆç‡æå‡50%
2. æˆæœ¬é™ä½30%ï¼Œèµ„æºåˆ©ç”¨ç‡å¤§å¹…æé«˜
3. ç”¨æˆ·ä½“éªŒæ˜¾è‘—æ”¹å–„ï¼Œå®¢æˆ·æ»¡æ„åº¦æå‡

## å®æ–½å»ºè®®

å¯¹äºæƒ³è¦åº”ç”¨{request.topic}çš„ä¼ä¸šï¼Œå»ºè®®ï¼š

- ä»å°è§„æ¨¡è¯•ç‚¹å¼€å§‹ï¼Œé€æ­¥æ‰©å±•
- é‡è§†å›¢é˜ŸåŸ¹è®­å’ŒçŸ¥è¯†ç§¯ç´¯
- å»ºç«‹å®Œå–„çš„ç›‘æ§å’Œè¯„ä¼°æœºåˆ¶

## æ€»ç»“

{request.topic}æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„å·¥ä½œå’Œç”Ÿæ´»æ–¹å¼ã€‚æ‹¥æŠ±å˜åŒ–ï¼Œæ‰èƒ½åœ¨æœªæ¥ç«äº‰ä¸­ç«‹äºä¸è´¥ä¹‹åœ°ã€‚

> **æ ¸å¿ƒè§‚ç‚¹**ï¼šæŠ€æœ¯åˆ›æ–°ä¸æ˜¯ç›®çš„ï¼Œè§£å†³å®é™…é—®é¢˜æ‰æ˜¯å…³é”®ã€‚

---

*æœ¬æ–‡ä¸ºæŠ€æœ¯åˆ†ææ–‡ç« ï¼Œæ—¨åœ¨å¸®åŠ©è¯»è€…äº†è§£{request.topic}çš„æ ¸å¿ƒä»·å€¼å’Œåº”ç”¨æ–¹æ³•ã€‚*
""",
                "casual": f"""# {request.title}

å˜¿ï¼Œæœ€è¿‘åœ¨ç ”ç©¶{request.topic}ï¼Œå‘ç°äº†ä¸€äº›å¾ˆæœ‰æ„æ€çš„äº‹æƒ…ï¼Œæƒ³å’Œå¤§å®¶èŠèŠã€‚

## ä¸ºä»€ä¹ˆè¦å…³æ³¨è¿™ä¸ªï¼Ÿ

è¯´å®è¯ï¼Œåˆšå¼€å§‹æˆ‘ä¹Ÿæœ‰ç‚¹æ‡µã€‚{request.topic}å¬èµ·æ¥å¥½åƒå¾ˆé«˜å¤§ä¸Šï¼Œä½†å…¶å®å’Œæˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»æ¯æ¯ç›¸å…³ã€‚

æ¯”å¦‚ï¼š

- æƒ³ä¸æƒ³æé«˜å·¥ä½œæ•ˆç‡ï¼Ÿ
- æƒ³ä¸æƒ³ç”¨æ›´å°‘çš„æ—¶é—´åšæ›´å¤šäº‹ï¼Ÿ
- æƒ³ä¸æƒ³åœ¨åŒé¾„äººä¸­è„±é¢–è€Œå‡ºï¼Ÿ

## æˆ‘çš„äº²èº«ç»å†

ä¸Šå‘¨æˆ‘å°è¯•äº†ä¸€ä¸ªæ–°æ–¹æ³•ï¼Œå°±æ˜¯åˆ©ç”¨{request.topic}æ¥è§£å†³ä¸€ä¸ªå›°æ‰°æˆ‘å¾ˆä¹…çš„é—®é¢˜ã€‚

ç»“æœä½ çŒœæ€ä¹ˆç€ï¼Ÿ

ç«Ÿç„¶åœ¨åŠå¤©å†…æå®šäº†ä¹‹å‰éœ€è¦ä¸¤å¤©æ‰èƒ½å®Œæˆçš„äº‹æƒ…ï¼ğŸ˜±

## æ€ä¹ˆæ“ä½œï¼Ÿ

å…¶å®ç‰¹åˆ«ç®€å•ï¼Œåªéœ€è¦ä¸‰æ­¥ï¼š

### ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å·¥ä½œ
å…ˆææ¸…æ¥šè‡ªå·±çš„éœ€æ±‚ï¼Œä¸è¦ç›²ç›®å¼€å§‹ã€‚

### ç¬¬äºŒæ­¥ï¼šå­¦ä¹ åŸºç¡€
äº†è§£æ ¸å¿ƒæ¦‚å¿µï¼Œä¸éœ€è¦å¤ªæ·±å…¥ï¼Œå¤Ÿç”¨å°±è¡Œã€‚

### ç¬¬ä¸‰æ­¥ï¼šå®è·µéªŒè¯
è¾¹åšè¾¹å­¦ï¼Œåœ¨å®è·µä¸­ä¸æ–­å®Œå–„ã€‚

## å°è´´å£«

- åˆ«æ€•çŠ¯é”™ï¼Œé”™è¯¯æ˜¯æœ€å¥½çš„è€å¸ˆ
- ä¿æŒå¥½å¥‡ï¼Œå¤šé—®ä¸ºä»€ä¹ˆ
- åˆ†äº«äº¤æµï¼Œå’Œä»–äººä¸€èµ·è¿›æ­¥

## å†™åœ¨æœ€å

{request.topic}å¹¶ä¸éš¾ï¼Œå…³é”®æ˜¯è¦å¼€å§‹è¡ŒåŠ¨ã€‚

> "åƒé‡Œä¹‹è¡Œï¼Œå§‹äºè¶³ä¸‹ã€‚"

å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæœ‰é—®é¢˜æ¬¢è¿åœ¨è¯„è®ºåŒºäº¤æµï¼ğŸ‘‹
""",
                "opinion": f"""# {request.title}

è¯´å®è¯ï¼Œæˆ‘å¯¹{request.topic}æœ‰è‡ªå·±çš„ä¸€äº›çœ‹æ³•ï¼Œå¯èƒ½å’Œå…¶ä»–äººä¸å¤ªä¸€æ ·ï¼Œä½†æˆ‘æƒ³è¯´å¥å¿ƒé‡Œè¯ã€‚

## è¡Œä¸šçš„ç°çŠ¶

ç°åœ¨å¤§å®¶éƒ½åœ¨è°ˆè®º{request.topic},ä»¿ä½›åªè¦æŒæ¡äº†å®ƒå°±èƒ½ç«‹åˆ»æˆåŠŸã€‚

ä½†æˆ‘è®¤ä¸ºï¼Œ**è¿™ç§æƒ³æ³•æ˜¯å±é™©çš„**ã€‚

## ä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´ï¼Ÿ

### 1. è¿‡åº¦å®£ä¼ 
å¾ˆå¤šäººæŠŠ{request.topic}å¹å¾—å¤ªç¥äº†ï¼Œä»¿ä½›å®ƒæ˜¯ä»€ä¹ˆä¸‡èƒ½é’¥åŒ™ã€‚

ä½†ç°å®æ˜¯ï¼š

- å¾ˆå¤šåŠŸèƒ½æ ¹æœ¬ç”¨ä¸ä¸Š
- å­¦ä¹ æˆæœ¬è¿œè¶…é¢„æœŸ
- å®é™…æ•ˆæœå¤§æ‰“æŠ˜æ‰£

### 2. å¿½è§†åŸºç¡€
ä¸ºäº†è¿½æ±‚æ‰€è°“çš„"çƒ­ç‚¹"ï¼Œå¾ˆå¤šäººè¿åŸºç¡€éƒ½æ²¡æ‰“ç‰¢å°±æ€¥ç€ä¸Šé¡¹ç›®ã€‚

ç»“æœæ˜¯ï¼š

- é¡¹ç›®è´¨é‡å ªå¿§
- åæœŸç»´æŠ¤æˆæœ¬é«˜
- æœ€ç»ˆè¿˜æ˜¯è¦é‡å¤´å†æ¥

## æˆ‘çš„è§‚ç‚¹

{request.topic}ç¡®å®æœ‰ä»·å€¼ï¼Œä½†ä¸æ˜¯ä¸‡èƒ½çš„ã€‚

**çœŸæ­£çš„ä»·å€¼åœ¨äºï¼š**

- è§£å†³å®é™…é—®é¢˜ï¼Œè€Œä¸æ˜¯è¿½çƒ­ç‚¹
- æå‡æ•ˆç‡ï¼Œè€Œä¸æ˜¯å¢åŠ å¤æ‚åº¦
- é•¿æœŸè§„åˆ’ï¼Œè€Œä¸æ˜¯çŸ­æœŸåˆ©ç›Š

## ç»™å¤§å®¶çš„å»ºè®®

å¦‚æœä½ åœ¨è€ƒè™‘è¦ä¸è¦å­¦ä¹ {request.topic}ï¼Œæˆ‘çš„å»ºè®®æ˜¯ï¼š

1. **å…ˆé—®è‡ªå·±ä¸ºä»€ä¹ˆ**ï¼šçœŸçš„æ˜¯éœ€è¦ï¼Œè¿˜æ˜¯åªæ˜¯è·Ÿé£ï¼Ÿ
2. **è¯„ä¼°æŠ•å…¥äº§å‡º**ï¼šå€¼å¾—èŠ±æ—¶é—´å—ï¼Ÿ
3. **æ‰¾åˆ°æœ€ä½³å®è·µ**ï¼šåˆ«è‡ªå·±çæŠ˜è…¾ï¼Œçœ‹çœ‹åˆ«äººæ€ä¹ˆåš

## æ€»ç»“

ä¸è¦è¢«è¡¨é¢ç°è±¡è¿·æƒ‘ï¼Œè¦ç”¨æ‰¹åˆ¤æ€§æ€ç»´çœ‹å¾…é—®é¢˜ã€‚

{request.topic}æœ‰å®ƒçš„ä»·å€¼ï¼Œä½†ä¹Ÿè¦ç†æ€§å¯¹å¾…ã€‚

> "ç‹¬ç«‹æ€è€ƒï¼Œæ¯”ç›²ç›®è·Ÿé£æ›´é‡è¦ã€‚"

---
*ä»¥ä¸Šçº¯å±ä¸ªäººè§‚ç‚¹ï¼Œæ¬¢è¿ç†æ€§è®¨è®ºã€‚*
"""
            }

            template = style_templates.get(request.style, style_templates["professional"])
            content = template.replace("{request.topic}", request.topic)
            summary = content[:200] + "..." if len(content) > 200 else content

            return ContentResponse(
                content=content,
                summary=summary,
                quality_score=75.0,
                sources=[request.topic]
            )

        raise HTTPException(
            status_code=502,
            detail={
                "message": "AI æ­£æ–‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–ç¨åé‡è¯•",
                "error_type": "ai_generate_content_failed",
                "allow_mock_fallback": False,
                "debug_error": str(e) if settings.DEBUG else None,
            }
        )


class BatchArticleRequest(BaseModel):
    """æ‰¹é‡ç”Ÿæˆæ–‡ç« è¯·æ±‚"""
    articles: List[Dict[str, str]] = Field(..., description="æ–‡ç« åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«titleã€topicã€styleã€length")
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„AIæ¨¡å‹")


class BatchArticleResponse(BaseModel):
    """æ‰¹é‡ç”Ÿæˆæ–‡ç« å“åº”"""
    results: List[Dict[str, Any]]
    success_count: int
    failed_count: int


@router.post("/generate-batch", response_model=BatchArticleResponse)
async def generate_batch_articles(request: BatchArticleRequest, db: AsyncSession = Depends(get_db)):
    """
    æ‰¹é‡ç”Ÿæˆæ–‡ç« ï¼ˆè§£å†³è‡ªåª’ä½“åˆ›ä½œè€…ç—›ç‚¹ï¼šæ‰¹é‡ç”Ÿäº§æ•ˆç‡ä½ï¼‰
    
    ä¸€æ¬¡æ€§ç”Ÿæˆå¤šç¯‡ä¸åŒä¸»é¢˜çš„æ–‡ç« ï¼Œæé«˜å†…å®¹ç”Ÿäº§æ•ˆç‡
    
    Args:
        request: æ‰¹é‡ç”Ÿæˆè¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
    
    Returns:
        æ‰¹é‡ç”Ÿæˆç»“æœ
    """
    try:
        config = await get_config_from_db(db)
        if not config or not config.api_key:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®AI API Key")
        
        logger.info(f"æ‰¹é‡ç”Ÿæˆæ–‡ç« ï¼Œå…± {len(request.articles)} ç¯‡")
        
        # åˆ›å»ºè‡ªå®šä¹‰ httpx å®¢æˆ·ç«¯
        http_client = httpx.AsyncClient(
            verify=False,
            timeout=httpx.Timeout(120.0, connect=10.0, read=60.0, write=60.0),
            follow_redirects=True,
            trust_env=False,
        )
        
        model = request.model or config.model or "deepseek-chat"
        base_url = config.base_url or "https://api.deepseek.com/v1"
        
        async with AsyncOpenAI(
            api_key=config.api_key,
            base_url=base_url,
            http_client=http_client
        ) as client:
            results = []
            
            for article_req in request.articles:
                try:
                    # æ„å»ºæç¤ºè¯
                    prompt = f"""è¯·æ’°å†™ä¸€ç¯‡å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{article_req.get('title')}
ä¸»é¢˜ï¼š{article_req.get('topic')}
å­—æ•°è¦æ±‚ï¼š{article_req.get('length', 'medium')}
é£æ ¼ï¼š{article_req.get('style', 'professional')}

è¦æ±‚ï¼š
1. å¼€ç¯‡å¸å¼•äººï¼Œæœ‰æ‚¬å¿µæˆ–ç—›ç‚¹
2. å†…å®¹æœ‰æ·±åº¦ï¼Œæä¾›å®ç”¨ä»·å€¼
3. ç»“æ„æ¸…æ™°ï¼Œæœ‰æ˜ç¡®çš„å°æ ‡é¢˜
4. ç»“å°¾æœ‰æ€»ç»“å’Œè¡ŒåŠ¨å·å¬

è¯·ä»¥Markdownæ ¼å¼è¾“å‡ºã€‚"""
                    
                    response = await client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‡ªåª’ä½“å†…å®¹åˆ›ä½œè€…ã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=4000
                    )
                    
                    content = response.choices[0].message.content
                    summary = content[:150] + "..." if len(content) > 150 else content
                    quality_score = _assess_quality(content)
                    
                    results.append({
                        "title": article_req.get('title'),
                        "topic": article_req.get('topic'),
                        "success": True,
                        "content": content,
                        "summary": summary,
                        "quality_score": quality_score
                    })
                    
                except Exception as e:
                    logger.error(f"ç”Ÿæˆæ–‡ç« å¤±è´¥: {e}")
                    results.append({
                        "title": article_req.get('title'),
                        "topic": article_req.get('topic'),
                        "success": False,
                        "error": str(e)
                    })
            
            success_count = sum(1 for r in results if r.get('success'))
            failed_count = len(results) - success_count
            
            logger.info(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ: æˆåŠŸ {success_count} ç¯‡, å¤±è´¥ {failed_count} ç¯‡")
            
            return BatchArticleResponse(
                results=results,
                success_count=success_count,
                failed_count=failed_count
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡ç”Ÿæˆæ–‡ç« å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ç”Ÿæˆæ–‡ç« å¤±è´¥: {str(e)}")


def _assess_quality(content: str) -> float:
    """è¯„ä¼°æ–‡ç« è´¨é‡"""
    score = 70.0
    
    # æ£€æŸ¥å­—æ•°
    word_count = len(content)
    if 800 <= word_count <= 3000:
        score += 10
    elif word_count < 500:
        score -= 20
    
    # æ£€æŸ¥ç»“æ„
    import re
    if re.search(r'#+\s+', content):
        score += 10
    
    # æ£€æŸ¥æ®µè½æ•°é‡
    paragraphs = content.split('\n\n')
    if len(paragraphs) >= 3:
        score += 10
    
    return min(100.0, max(0.0, score))


@router.post("/auto-generate", response_model=dict)
async def auto_generate(request: AutoGenerateRequest, db: AsyncSession = Depends(get_db)):
    """
    ä¸€é”®å…¨è‡ªåŠ¨ç”Ÿæˆæ–‡ç« 
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. ç”Ÿæˆæ ‡é¢˜
    2. ç”Ÿæˆæ­£æ–‡
    3. å¤„ç†å°é¢å›¾
    4. å‘å¸ƒåˆ°å¾®ä¿¡ï¼ˆå¯é€‰ï¼‰
    
    Args:
        request: å…¨è‡ªåŠ¨ç”Ÿæˆè¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
    
    Returns:
        ç”Ÿæˆç»“æœ
    """
    try:
        if not isinstance(ai_writer_service, _DefaultAIWriterService):
            titles = await ai_writer_service.generate_titles(topic=request.topic, count=1, model=request.model)
            selected_title = titles[0]["title"] if titles else f"{request.topic}è§‚å¯Ÿ"
            generated = await ai_writer_service.generate_content(
                topic=request.topic,
                title=selected_title,
                style="professional",
                length="medium",
                model=request.model,
            )

            result = {
                "steps": [
                    {"step": 1, "status": "completed", "title": selected_title},
                    {"step": 2, "status": "completed", "summary": generated.get("summary", "")},
                ],
                "success": True,
                "article_id": None,
                "wechat_draft_id": None,
                "article": {
                    "title": selected_title,
                    "content": generated.get("content", ""),
                    "summary": generated.get("summary", ""),
                    "quality_score": generated.get("quality_score", 0),
                },
            }

            if request.enable_wechat_publish:
                access_token = await wechat_service.get_access_token(app_id="", app_secret="")
                draft_id = await wechat_service.create_draft(
                    access_token=access_token,
                    title=selected_title,
                    author="æ‹¾è´çŒ«",
                    digest=generated.get("summary", ""),
                    content=generated.get("content", ""),
                    cover_media_id="",
                )
                result["steps"].append({"step": 3, "status": "completed", "draft_id": draft_id})
                result["wechat_draft_id"] = draft_id

            return result

        # ä»æ•°æ®åº“è·å–é…ç½®
        config = await get_config_from_db(db)
        if not config or not config.api_key:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®AI API Key")
        
        logger.info(f"ä¸€é”®å…¨è‡ªåŠ¨ç”Ÿæˆï¼Œä¸»é¢˜: {request.topic}")
        
        result = {
            "steps": [],
            "success": False,
            "article_id": None,
            "wechat_draft_id": None
        }
        
        # æ­¥éª¤1: ç”Ÿæˆæ ‡é¢˜
        result["steps"].append({"step": 1, "status": "running", "message": "æ­£åœ¨ç”Ÿæˆæ ‡é¢˜..."})

        # é€‰æ‹©æ¨¡å‹å’ŒåŸºç¡€URLï¼Œä½¿ç”¨é»˜è®¤å€¼ç¡®ä¿é…ç½®å®Œæ•´
        model = request.model or config.model or "deepseek-chat"
        base_url = config.base_url or "https://api.deepseek.com/v1"

        logger.info(f"ä½¿ç”¨AIæ¨¡å‹: {model}, APIåœ°å€: {base_url}")

        # åˆ›å»ºè‡ªå®šä¹‰ httpx å®¢æˆ·ç«¯ï¼ˆä¿®å¤ Windows SSL é—®é¢˜ï¼‰
        http_client = httpx.AsyncClient(
            verify=False,  # ç¦ç”¨ SSL éªŒè¯ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
            timeout=httpx.Timeout(300.0, connect=10.0),  # å¢åŠ åˆ°300ç§’ï¼Œç”Ÿæˆæ­£æ–‡éœ€è¦æ›´é•¿æ—¶é—´
            follow_redirects=True,
            trust_env=False,
        )
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨async withè‡ªåŠ¨ç®¡ç†è¿æ¥ï¼‰
        async with AsyncOpenAI(
            api_key=config.api_key,
            base_url=base_url,
            http_client=http_client
        ) as client:
            prompt = f"""è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆ 1 ä¸ªå¸å¼•äººçš„æ–‡ç« æ ‡é¢˜ï¼Œè¦æ±‚ï¼š
1. æ ‡é¢˜ç®€æ´æœ‰åŠ›ï¼Œèƒ½å¸å¼•ç‚¹å‡»
2. æ ‡é¢˜é•¿åº¦åœ¨15-25å­—ä¹‹é—´
3. ä½“ç°ç§‘æŠ€æ„Ÿå’Œå‰æ²¿æ€§
4. é€‚åˆå¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ

ä¸»é¢˜ï¼š{request.topic}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{"title": "æ ‡é¢˜1", "click_rate": 85}}
]
click_rateä¸ºé¢„æµ‹ç‚¹å‡»ç‡ï¼ˆ0-100ï¼‰"""

            response = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¬ä¼—å·æ ‡é¢˜åˆ›ä½œä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )

            content = response.choices[0].message.content
            import json, re
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)
            titles = json.loads(content)

            if not titles:
                raise HTTPException(status_code=500, detail="ç”Ÿæˆæ ‡é¢˜å¤±è´¥")

            selected_title = titles[0]["title"]
            result["steps"][0]["status"] = "completed"
            result["steps"][0]["title"] = selected_title
            logger.info(f"ç”Ÿæˆæ ‡é¢˜å®Œæˆ: {selected_title}")

            # æ­¥éª¤2: ç”Ÿæˆæ­£æ–‡
            result["steps"].append({"step": 2, "status": "running", "message": "æ­£åœ¨ç”Ÿæˆæ­£æ–‡..."})

            length_map = {
                "short": "800-1000å­—",
                "medium": "1500-2000å­—",
                "long": "2500-3000å­—"
            }

            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æ’°å†™ä¸€ç¯‡å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{selected_title}
ä¸»é¢˜ï¼š{request.topic}
å­—æ•°è¦æ±‚ï¼š{length_map['medium']}
é£æ ¼è¦æ±‚ï¼šä¸“ä¸šä¸¥è°¨ï¼Œæ·±åº¦åˆ†æ

æ–‡ç« è¦æ±‚ï¼š
1. å¼€å¤´è¦æœ‰å¸å¼•äººçš„å¼•è¨€
2. æ­£æ–‡ç»“æ„æ¸…æ™°ï¼Œæœ‰å°æ ‡é¢˜
3. å†…å®¹è¦æœ‰æ·±åº¦å’Œè§è§£
4. ç»“å°¾è¦æœ‰æ€»ç»“å’Œå±•æœ›
5. é€‚åˆæ‰‹æœºé˜…è¯»ï¼Œæ®µè½ä¸å®œè¿‡é•¿

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""

            response = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿æ’°å†™æ·±åº¦ç§‘æŠ€æ–‡ç« ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )

            article_content = response.choices[0].message.content
            summary = article_content[:100] + "..." if len(article_content) > 100 else article_content
            quality_score = _assess_quality(article_content)

            result["steps"][1]["status"] = "completed"
            result["steps"][1]["summary"] = summary
            logger.info("ç”Ÿæˆæ­£æ–‡å®Œæˆ")
        
        # æ­¥éª¤3: å¤„ç†å°é¢å›¾
        result["steps"].append({"step": 3, "status": "running", "message": "æ­£åœ¨å¤„ç†å°é¢å›¾..."})
        image_path = await image_generation_service.generate_article_cover(selected_title[:20])
        
        result["steps"][2]["status"] = "completed"
        result["steps"][2]["image_path"] = image_path
        logger.info(f"å°é¢å›¾å¤„ç†å®Œæˆ: {image_path}")
        
        # æ­¥éª¤4: å‘å¸ƒåˆ°å¾®ä¿¡ï¼ˆå¯é€‰ï¼‰
        if request.enable_wechat_publish:
            result["steps"].append({"step": 4, "status": "running", "message": "æ­£åœ¨å‘å¸ƒåˆ°å¾®ä¿¡..."})
            
            if not config.wechat_app_id or not config.wechat_app_secret:
                raise HTTPException(status_code=400, detail="æœªé…ç½®å¾®ä¿¡AppIDå’ŒAppSecret")
            
            # è·å–access_token
            access_token = await wechat_service.get_access_token(
                app_id=config.wechat_app_id,
                app_secret=config.wechat_app_secret
            )
            
            # ä¸Šä¼ å°é¢å›¾
            media_id = ""
            if image_path:
                media_id = await wechat_service.upload_media(
                    access_token=access_token,
                    media_type="image",
                    file_path=image_path
                )
                result["steps"][3]["media_id"] = media_id
            
            # åˆ›å»ºè‰ç¨¿
            draft_id = await wechat_service.create_draft(
                access_token=access_token,
                title=selected_title,
                author="æ‹¾è´çŒ«",
                digest=summary,
                content=article_content,
                cover_media_id=media_id
            )
            
            result["steps"][3]["status"] = "completed"
            result["wechat_draft_id"] = draft_id
            logger.info(f"å¾®ä¿¡è‰ç¨¿åˆ›å»ºå®Œæˆ: {draft_id}")
        
        result["success"] = True
        result["article"] = {
            "title": selected_title,
            "content": article_content,
            "summary": summary,
            "quality_score": quality_score
        }
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸€é”®ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸€é”®ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.get("/providers", response_model=List[Dict[str, Any]])
async def get_ai_providers(db: AsyncSession = Depends(get_db)):
    """
    è·å–AIæä¾›å•†åˆ—è¡¨

    è¿”å›æ‰€æœ‰å¯ç”¨çš„AIæä¾›å•†åŠå…¶é…ç½®çŠ¶æ€

    Returns:
        AIæä¾›å•†åˆ—è¡¨
    """
    try:
        # ä»æ•°æ®åº“è·å–é…ç½®
        config = await get_config_from_db(db)

        # å®šä¹‰æ‰€æœ‰æ”¯æŒçš„AIæä¾›å•†
        providers = [
            {
                "id": "deepseek",
                "name": "DeepSeek",
                "display_name": "DeepSeek (æ·±åº¦æ±‚ç´¢)",
                "description": "å›½äº§å¤§è¯­è¨€æ¨¡å‹ï¼Œæ€§ä»·æ¯”é«˜ï¼Œé€‚åˆä¸­æ–‡åˆ›ä½œ",
                "configured": False,
                "model": "deepseek-chat",
                "base_url": "https://api.deepseek.com/v1"
            },
            {
                "id": "openai",
                "name": "OpenAI",
                "display_name": "OpenAI GPT",
                "description": "ä¸šç•Œé¢†å…ˆçš„AIæ¨¡å‹ï¼Œè´¨é‡ç¨³å®š",
                "configured": False,
                "model": "gpt-4-turbo-preview",
                "base_url": "https://api.openai.com/v1"
            },
            {
                "id": "gemini",
                "name": "Gemini",
                "display_name": "Google Gemini",
                "description": "Googleæœ€æ–°AIæ¨¡å‹ï¼Œæ”¯æŒå¤šæ¨¡æ€",
                "configured": False,
                "model": "gemini-pro",
                "base_url": "https://generativelanguage.googleapis.com/v1beta"
            },
            {
                "id": "claude",
                "name": "Claude",
                "display_name": "Anthropic Claude",
                "description": "å®‰å…¨æ€§é«˜ï¼Œé€‚åˆé•¿æ–‡æœ¬åˆ›ä½œ",
                "configured": False,
                "model": "claude-3-opus",
                "base_url": "https://api.anthropic.com/v1"
            }
        ]

        # æ£€æŸ¥å“ªäº›æä¾›å•†å·²é…ç½®
        if config and config.api_key:
            current_provider = config.ai_provider or "deepseek"

            # æ›´æ–°å½“å‰æä¾›å•†çš„é…ç½®çŠ¶æ€
            for provider in providers:
                if provider["id"] == current_provider:
                    provider["configured"] = True
                    provider["model"] = config.model or provider["model"]
                    provider["base_url"] = config.base_url or provider["base_url"]
                    break

        logger.info(f"è¿”å›AIæä¾›å•†åˆ—è¡¨ï¼Œå…± {len(providers)} ä¸ªæä¾›å•†ï¼Œ{sum(p['configured'] for p in providers)} ä¸ªå·²é…ç½®")

        return providers

    except Exception as e:
        logger.error(f"è·å–AIæä¾›å•†åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–AIæä¾›å•†åˆ—è¡¨å¤±è´¥: {str(e)}")


# ========== å…¼å®¹æ€§è·¯ç”± ==========

@router.post("/score-title", response_model=TitleScoreResponse)
async def score_title(request: TitleScoreRequest, db: AsyncSession = Depends(get_db)):
    """
    è¯„åˆ†æ ‡é¢˜è´¨é‡å’Œé¢„ä¼°ç‚¹å‡»ç‡
    
    ä½¿ç”¨AIæ¨¡å‹ä»å¤šä¸ªç»´åº¦è¯„ä¼°æ ‡é¢˜è´¨é‡ï¼ŒåŒ…æ‹¬ï¼š
    - å¸å¼•åŠ›ï¼ˆå¥½å¥‡å¿ƒç¼ºå£ã€æƒ…æ„Ÿè§¦å‘ï¼‰
    - æ¸…æ™°åº¦ï¼ˆæ˜¯å¦æ˜ç¡®ä¼ è¾¾ä¸»é¢˜ï¼‰
    - é•¿åº¦ä¼˜åŒ–ï¼ˆæ˜¯å¦é€‚ä¸­ï¼‰
    - å…³é”®è¯ä½¿ç”¨
    - æ•°å­—åŒ–ç¨‹åº¦
    
    Args:
        request: æ ‡é¢˜è¯„åˆ†è¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        è¯„åˆ†ç»“æœå’Œå»ºè®®
    """
    try:
        # ä»æ•°æ®åº“è·å–é…ç½®
        config = await get_config_from_db(db)
        if not config or not config.api_key:
            raise HTTPException(status_code=400, detail="è¯·å…ˆåœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½®AIå‚æ•°")
        
        logger.info(f"è¯„åˆ†æ ‡é¢˜: {request.title}")
        
        model = request.model or config.model or "deepseek-chat"
        base_url = config.base_url or "https://api.deepseek.com/v1"
        
        # åˆ›å»ºAIå®¢æˆ·ç«¯
        http_client = httpx.AsyncClient(
            verify=False,
            timeout=httpx.Timeout(60.0, connect=10.0),
            trust_env=False,
        )
        
        client = AsyncOpenAI(
            api_key=config.api_key,
            base_url=base_url,
            http_client=http_client
        )
        
        # æ„å»ºè¯„åˆ†æç¤ºè¯
        topic_context = f"æ–‡ç« ä¸»é¢˜ï¼š{request.topic}\n" if request.topic else ""
        prompt = f"""è¯·ä½œä¸ºèµ„æ·±è‡ªåª’ä½“è¿è¥ä¸“å®¶ï¼Œå¯¹ä»¥ä¸‹æ ‡é¢˜è¿›è¡Œä¸“ä¸šè¯„åˆ†ã€‚

{topic_context}å¾…è¯„åˆ†æ ‡é¢˜ï¼š"{request.title}"

è¯·ä»ä»¥ä¸‹5ä¸ªç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆæ¯é¡¹0-20åˆ†ï¼Œæ€»åˆ†100åˆ†ï¼‰ï¼š
1. å¸å¼•åŠ›ï¼šæ˜¯å¦èƒ½æ¿€å‘è¯»è€…ç‚¹å‡»æ¬²æœ›ï¼ˆå¥½å¥‡å¿ƒã€æƒ…æ„Ÿè§¦å‘ã€æ‚¬å¿µè®¾ç½®ï¼‰
2. æ¸…æ™°åº¦ï¼šæ˜¯å¦æ˜ç¡®ä¼ è¾¾æ–‡ç« æ ¸å¿ƒå†…å®¹ï¼ˆé¿å…æ ‡é¢˜å…šï¼ŒçœŸå®åæ˜ å†…å®¹ï¼‰
3. é•¿åº¦ï¼šå­—æ•°æ˜¯å¦é€‚ä¸­ï¼ˆä¸­æ–‡æ ‡é¢˜15-25å­—æœ€ä½³ï¼‰
4. å…³é”®è¯ï¼šæ˜¯å¦åŒ…å«çƒ­é—¨å…³é”®è¯æˆ–è¡Œä¸šæœ¯è¯­
5. æ•°å­—åŒ–ï¼šæ˜¯å¦æœ‰æ•ˆä½¿ç”¨æ•°å­—ã€æ•°æ®å¢å¼ºè¯´æœåŠ›

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "score": æ€»åˆ†(0-100),
    "click_rate": é¢„ä¼°ç‚¹å‡»ç‡(0-100),
    "analysis": "ç»¼åˆè¯„ä»·ï¼ˆ50å­—ä»¥å†…ï¼‰",
    "dimensions": {{
        "å¸å¼•åŠ›": åˆ†æ•°,
        "æ¸…æ™°åº¦": åˆ†æ•°,
        "é•¿åº¦": åˆ†æ•°,
        "å…³é”®è¯": åˆ†æ•°,
        "æ•°å­—åŒ–": åˆ†æ•°
    }},
    "suggestions": ["ä¼˜åŒ–å»ºè®®1", "ä¼˜åŒ–å»ºè®®2", "ä¼˜åŒ–å»ºè®®3"]
}}

æ³¨æ„ï¼šclick_rateæ˜¯åŸºäºæ ‡é¢˜è´¨é‡çš„é¢„ä¼°ç‚¹å‡»ç‡ï¼Œä¼˜ç§€æ ‡é¢˜å¯è¾¾15-25%ï¼Œæ™®é€šæ ‡é¢˜5-10%ï¼Œè¾ƒå·®æ ‡é¢˜<5%"""

        # è°ƒç”¨AI
        response = await client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èµ„æ·±è‡ªåª’ä½“è¿è¥ä¸“å®¶ï¼Œæ“…é•¿æ ‡é¢˜ä¼˜åŒ–å’Œæµé‡åˆ†æã€‚åªè¿”å›JSONæ ¼å¼æ•°æ®ï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=800
        )
        
        await http_client.aclose()
        
        # è§£æAIå“åº”
        content = response.choices[0].message.content
        
        # æå–JSON
        try:
            # å°è¯•ç›´æ¥è§£æ
            result = json.loads(content)
        except json.JSONDecodeError:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                result = json.loads(json_match.group())
            else:
                raise ValueError("æ— æ³•è§£æAIå“åº”")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['score', 'click_rate', 'analysis', 'dimensions', 'suggestions']
        for field in required_fields:
            if field not in result:
                result[field] = [] if field == 'suggestions' else {} if field == 'dimensions' else 0
        
        logger.info(f"æ ‡é¢˜è¯„åˆ†å®Œæˆ: {request.title[:20]}... å¾—åˆ†: {result['score']}")
        
        return TitleScoreResponse(
            score=result['score'],
            click_rate=result['click_rate'],
            analysis=result['analysis'],
            dimensions=result['dimensions'],
            suggestions=result['suggestions']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ‡é¢˜è¯„åˆ†å¤±è´¥: {str(e)}")
        # è¿”å›ä¸€ä¸ªé»˜è®¤å“åº”è€Œä¸æ˜¯æŠ¥é”™
        return TitleScoreResponse(
            score=70,
            click_rate=8.5,
            analysis="è¯„åˆ†æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®æ ‡é¢˜ä¿æŒç®€æ´æ˜äº†ï¼Œçªå‡ºæ ¸å¿ƒä»·å€¼ã€‚",
            dimensions={
                "å¸å¼•åŠ›": 14,
                "æ¸…æ™°åº¦": 15,
                "é•¿åº¦": 13,
                "å…³é”®è¯": 14,
                "æ•°å­—åŒ–": 14
            },
            suggestions=[
                "æ ‡é¢˜æ§åˆ¶åœ¨15-25å­—ä¹‹é—´",
                "ä½¿ç”¨æ•°å­—å¢å¼ºè¯´æœåŠ›",
                "æ·»åŠ æƒ…æ„Ÿè§¦å‘è¯æå‡ç‚¹å‡»ç‡",
                "æ˜ç¡®æ–‡ç« æ ¸å¿ƒå–ç‚¹"
            ]
        )


# ========== å…¼å®¹æ€§è·¯ç”± ==========

# ä¸ºäº†å‘åå…¼å®¹,æ·»åŠ  /api/unified-ai/providers è·¯ç”±åˆ«å
# è¿™æ˜¯å› ä¸ºå†å²åŸå› ,å‰ç«¯ä»£ç å¯èƒ½ä½¿ç”¨ /api/unified-ai/providers è·¯å¾„

providers_alias_router = APIRouter()


@providers_alias_router.get("/providers", response_model=List[Dict[str, Any]])
async def get_ai_providers_alias(db: AsyncSession = Depends(get_db)):
    """
    è·å–AIæä¾›å•†åˆ—è¡¨ (å…¼å®¹æ€§è·¯ç”±)

    è¿™æ˜¯ /api/ai/providers çš„åˆ«å,ç”¨äºå‘åå…¼å®¹
    å®é™…åŠŸèƒ½ç”± get_ai_providers() å‡½æ•°å®ç°

    Returns:
        AIæä¾›å•†åˆ—è¡¨
    """
    return await get_ai_providers(db)


# æ³¨æ„:æ­¤è·¯ç”±éœ€è¦åœ¨ main.py ä¸­å•ç‹¬æ³¨å†Œ
# app.include_router(providers_alias_router, prefix="/api/unified-ai", tags=["AIæœåŠ¡-å…¼å®¹"])
