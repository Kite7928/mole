"""
æ–‡ç« æ’ç‰ˆä¼˜åŒ–æœåŠ¡
é’ˆå¯¹è‡ªåª’ä½“æ–‡ç« è¿›è¡Œæ’ç‰ˆä¼˜åŒ–ï¼Œæå‡é˜…è¯»ä½“éªŒ
"""

import re
from typing import List, Dict, Any, Tuple
from pydantic import BaseModel


class FormatOptions(BaseModel):
    """æ’ç‰ˆé€‰é¡¹"""
    add_emoji: bool = True
    highlight_key_points: bool = True
    add_subtitles: bool = True
    optimize_paragraphs: bool = True
    add_reading_guide: bool = False
    wechat_style: bool = True


class ArticleFormatter:
    """æ–‡ç« æ’ç‰ˆä¼˜åŒ–å™¨"""
    
    # Emojiæ˜ å°„
    EMOJI_MAP = {
        "é‡è¦": "ğŸ“Œ",
        "æ³¨æ„": "âš ï¸",
        "æç¤º": "ğŸ’¡",
        "å»ºè®®": "âœ…",
        "è­¦å‘Š": "ğŸš¨",
        "ç–‘é—®": "â“",
        "æ€»ç»“": "ğŸ“",
        "æ­¥éª¤": "ğŸ”¢",
        "ç¤ºä¾‹": "ğŸ“‹",
        "å¥½å¤„": "âœ¨",
        "åå¤„": "âŒ",
        "å¯¹æ¯”": "âš–ï¸",
        "æŠ€å·§": "ğŸ¯",
        "ç§˜å¯†": "ğŸ¤«",
        "çœŸç›¸": "ğŸ”",
    }
    
    # é‡ç‚¹è¯é«˜äº®
    KEYWORDS = [
        "å…³é”®", "æ ¸å¿ƒ", "é‡ç‚¹", "æœ¬è´¨", "ç§˜è¯€",
        "å¿…é¡»", "ä¸€å®š", "ç»å¯¹", "åƒä¸‡", "è®°ä½",
        "æ³¨æ„", "è­¦æƒ•", "å°å¿ƒ", "é¿å…",
        "æ¨è", "å»ºè®®", "é¦–é€‰", "æœ€ä½³",
        "çœŸç›¸", "æ­ç§˜", "ç‹¬å®¶", "å†…éƒ¨",
    ]
    
    @staticmethod
    def format_for_wechat(content: str, options: FormatOptions = None) -> str:
        """
        æ ¼å¼åŒ–ä¸ºå¾®ä¿¡æ–‡ç« é£æ ¼
        
        Args:
            content: åŸå§‹å†…å®¹
            options: æ’ç‰ˆé€‰é¡¹
        
        Returns:
            æ ¼å¼åŒ–åçš„å†…å®¹
        """
        if options is None:
            options = FormatOptions()
        
        result = content
        
        # 1. ä¼˜åŒ–æ®µè½é•¿åº¦
        if options.optimize_paragraphs:
            result = ArticleFormatter._optimize_paragraphs(result)
        
        # 2. æ·»åŠ å°æ ‡é¢˜
        if options.add_subtitles:
            result = ArticleFormatter._add_subtitles(result)
        
        # 3. é«˜äº®é‡ç‚¹
        if options.highlight_key_points:
            result = ArticleFormatter._highlight_keywords(result)
        
        # 4. æ·»åŠ emoji
        if options.add_emoji:
            result = ArticleFormatter._add_emoji(result)
        
        # 5. å¾®ä¿¡ç‰¹æ®Šæ ¼å¼
        if options.wechat_style:
            result = ArticleFormatter._apply_wechat_style(result)
        
        return result
    
    @staticmethod
    def _optimize_paragraphs(content: str) -> str:
        """ä¼˜åŒ–æ®µè½é•¿åº¦ï¼Œé€‚åˆæ‰‹æœºé˜…è¯»"""
        paragraphs = content.split('\n\n')
        optimized = []
        
        for para in paragraphs:
            para = para.strip()
            if not para:
                continue
            
            # å¦‚æœæ®µè½å¤ªé•¿ï¼Œæ‹†åˆ†æˆå¤šä¸ªå°æ®µè½
            if len(para) > 200:
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', para)
                current_para = ""
                
                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    if i + 1 < len(sentences):
                        sentence += sentences[i + 1]
                    
                    if len(current_para) + len(sentence) > 150:
                        if current_para:
                            optimized.append(current_para)
                        current_para = sentence
                    else:
                        current_para += sentence
                
                if current_para:
                    optimized.append(current_para)
            else:
                optimized.append(para)
        
        return '\n\n'.join(optimized)
    
    @staticmethod
    def _add_subtitles(content: str) -> str:
        """è‡ªåŠ¨æ·»åŠ å°æ ‡é¢˜"""
        paragraphs = content.split('\n\n')
        result = []
        
        for i, para in enumerate(paragraphs):
            para = para.strip()
            if not para:
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ ‡é¢˜
            if para.startswith('#') or para.startswith('ã€') or para.startswith('**'):
                result.append(para)
                continue
            
            # åœ¨é•¿å†…å®¹å‰æ·»åŠ å¼•å¯¼æ€§å°æ ‡é¢˜ï¼ˆæ¯3-4æ®µï¼‰
            if i > 0 and i % 3 == 0 and len(para) > 100:
                # æå–å…³é”®ä¿¡æ¯ç”Ÿæˆå°æ ‡é¢˜
                first_sentence = para.split('ã€‚')[0][:20]
                if len(first_sentence) > 10:
                    subtitle = f"**ğŸ’¡ {first_sentence}...**"
                    result.append(subtitle)
            
            result.append(para)
        
        return '\n\n'.join(result)
    
    @staticmethod
    def _highlight_keywords(content: str) -> str:
        """é«˜äº®å…³é”®è¯"""
        result = content
        
        for keyword in ArticleFormatter.KEYWORDS:
            # ä½¿ç”¨ç²—ä½“æ ‡è®°å…³é”®è¯
            pattern = f"({keyword})"
            replacement = r"**\1**"
            result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
        
        return result
    
    @staticmethod
    def _add_emoji(content: str) -> str:
        """åœ¨åˆé€‚ä½ç½®æ·»åŠ emoji"""
        result = content
        
        # åœ¨æ®µè½å¼€å¤´æ·»åŠ ç›¸å…³emoji
        for text, emoji in ArticleFormatter.EMOJI_MAP.items():
            if text in result[:50]:  # åªåœ¨æ–‡ç« å¼€å¤´åŒ¹é…
                result = emoji + " " + result
                break
        
        # ä¸ºæ•°å­—åˆ—è¡¨æ·»åŠ emoji
        result = re.sub(r'^(\d+)\.\s+', r'ğŸ”¢ \1. ', result, flags=re.MULTILINE)
        
        return result
    
    @staticmethod
    def _apply_wechat_style(content: str) -> str:
        """åº”ç”¨å¾®ä¿¡æ–‡ç« ç‰¹æ®Šæ ¼å¼"""
        # æ·»åŠ å¼•ç”¨æ¡†
        content = re.sub(
            r'^(?:å¼•ç”¨|åŸæ–‡|æ‘˜è¦)[ï¼š:]\s*(.+)$',
            r'> ğŸ“Œ \1',
            content,
            flags=re.MULTILINE
        )
        
        # é‡ç‚¹æ ‡æ³¨æ¡†
        content = re.sub(
            r'^(?:é‡ç‚¹|æ ¸å¿ƒ|æ€»ç»“)[ï¼š:]\s*(.+)$',
            r'**ğŸ“ é‡ç‚¹æç¤º**\n\n\1',
            content,
            flags=re.MULTILINE
        )
        
        return content
    
    @staticmethod
    def extract_keywords(content: str, top_n: int = 5) -> List[Dict[str, Any]]:
        """
        æå–æ–‡ç« å…³é”®è¯
        
        Args:
            content: æ–‡ç« å†…å®¹
            top_n: è¿”å›å…³é”®è¯æ•°é‡
        
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆåŸºäºè¯é¢‘ï¼‰
        import jieba
        
        # åˆ†è¯
        words = jieba.lcut(content)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'])
        filtered_words = [w for w in words if len(w) > 1 and w not in stop_words]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in filtered_words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # æ’åºå¹¶è¿”å›top_n
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        keywords = []
        for word, freq in sorted_words[:top_n]:
            keywords.append({
                "word": word,
                "frequency": freq,
                "suitable_for_tag": len(word) <= 10  # é€‚åˆä½œä¸ºæ ‡ç­¾
            })
        
        return keywords
    
    @staticmethod
    def generate_tags(content: str, title: str = "") -> List[str]:
        """
        ç”Ÿæˆæ–‡ç« æ ‡ç­¾/è¯é¢˜
        
        Args:
            content: æ–‡ç« å†…å®¹
            title: æ–‡ç« æ ‡é¢˜
        
        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        tags = []
        
        # åŸºäºæ ‡é¢˜æå–æ ‡ç­¾
        if title:
            # ä½¿ç”¨jiebaæå–å…³é”®è¯
            import jieba.analyse
            title_tags = jieba.analyse.extract_tags(title, topK=3, allowPOS=('n', 'ns', 'nt', 'nw', 'nz'))
            tags.extend(title_tags)
        
        # åŸºäºå†…å®¹æå–
        import jieba.analyse
        content_tags = jieba.analyse.extract_tags(content, topK=5, allowPOS=('n', 'ns', 'nt', 'nw', 'nz'))
        tags.extend(content_tags)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_tags = list(set(tags))[:8]
        
        return unique_tags
    
    @staticmethod
    def calculate_reading_time(content: str) -> Dict[str, Any]:
        """
        è®¡ç®—é˜…è¯»æ—¶é—´
        
        Args:
            content: æ–‡ç« å†…å®¹
        
        Returns:
            é˜…è¯»æ—¶é—´ä¿¡æ¯
        """
        # ç»Ÿè®¡å­—æ•°
        char_count = len(content.replace(' ', '').replace('\n', ''))
        word_count = len(content.split())
        
        # è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆæŒ‰300å­—/åˆ†é’Ÿï¼‰
        reading_minutes = max(1, round(char_count / 300))
        
        return {
            "char_count": char_count,
            "word_count": word_count,
            "reading_minutes": reading_minutes,
            "reading_time_text": f"çº¦{reading_minutes}åˆ†é’Ÿ",
            "difficulty": "ç®€å•" if char_count < 800 else "é€‚ä¸­" if char_count < 2000 else "æ·±åº¦"
        }
    
    @staticmethod
    def generate_summary(content: str, max_length: int = 150) -> str:
        """
        ç”Ÿæˆæ–‡ç« æ‘˜è¦
        
        Args:
            content: æ–‡ç« å†…å®¹
            max_length: æœ€å¤§é•¿åº¦
        
        Returns:
            æ‘˜è¦
        """
        # ç®€å•çš„æ‘˜è¦ç”Ÿæˆï¼ˆå–å‰å‡ ä¸ªå¥å­ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        summary = ""
        
        for sentence in sentences:
            if len(summary) + len(sentence) > max_length:
                break
            summary += sentence + "ã€‚"
        
        return summary[:max_length] + "..." if len(summary) > max_length else summary


# æœåŠ¡å®ä¾‹
article_formatter = ArticleFormatter()
